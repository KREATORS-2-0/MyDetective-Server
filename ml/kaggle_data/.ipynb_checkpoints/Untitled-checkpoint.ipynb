{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2944ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "# from entropy import spectral_entropy\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2caed856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to\n",
    "Ravdess = \"data/Ravdess/audio_speech_actors_01-24\"\n",
    "Crema = \"data/Crema\"\n",
    "Savee = \"data/Savee/AudioData/\"\n",
    "Tess = \"data/Tess/TESS Toronto emotional speech set data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "86e51e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a53f6bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Path\n",
       "0    angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "1     fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "2     fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "3    angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "4  disgust  data/Ravdess/audio_speech_actors_01-24/Actor_1..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(os.path.join(Ravdess, dir))\n",
    "    for wav in actor:\n",
    "        info = wav.partition(\".wav\")[0].split(\"-\")\n",
    "        emotion = int(info[2])\n",
    "        emotion_df.append((emotion, os.path.join(Ravdess, dir, wav)))\n",
    "        \n",
    "Ravdess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Ravdess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Ravdess_df.Emotion.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "94f202df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c7139ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Crema/1022_ITS_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Crema/1037_ITS_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>data/Crema/1060_ITS_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>data/Crema/1075_ITS_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Crema/1073_IOM_DIS_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                            Path\n",
       "0    angry  data/Crema/1022_ITS_ANG_XX.wav\n",
       "1    angry  data/Crema/1037_ITS_ANG_XX.wav\n",
       "2  neutral  data/Crema/1060_ITS_NEU_XX.wav\n",
       "3  neutral  data/Crema/1075_ITS_NEU_XX.wav\n",
       "4  disgust  data/Crema/1073_IOM_DIS_XX.wav"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df = []\n",
    "\n",
    "for wav in os.listdir(Crema):\n",
    "    info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "    if info[2] == 'SAD':\n",
    "        emotion_df.append((\"sad\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'ANG':\n",
    "        emotion_df.append((\"angry\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'DIS':\n",
    "        emotion_df.append((\"disgust\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'FEA':\n",
    "        emotion_df.append((\"fear\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'HAP':\n",
    "        emotion_df.append((\"happy\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'NEU':\n",
    "        emotion_df.append((\"neutral\", Crema + \"/\" + wav))\n",
    "    else:\n",
    "        emotion_df.append((\"unknown\", Crema + \"/\" + wav))\n",
    "\n",
    "\n",
    "Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d7bab274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "510912a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Tess/TESS Toronto emotional speech set da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Tess/TESS Toronto emotional speech set da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Tess/TESS Toronto emotional speech set da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Tess/TESS Toronto emotional speech set da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Tess/TESS Toronto emotional speech set da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Path\n",
       "0  disgust  data/Tess/TESS Toronto emotional speech set da...\n",
       "1  disgust  data/Tess/TESS Toronto emotional speech set da...\n",
       "2  disgust  data/Tess/TESS Toronto emotional speech set da...\n",
       "3  disgust  data/Tess/TESS Toronto emotional speech set da...\n",
       "4  disgust  data/Tess/TESS Toronto emotional speech set da..."
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    for wav in os.listdir(os.path.join(Tess, dir)):\n",
    "        \n",
    "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "        \n",
    "        emo = info[2]\n",
    "        \n",
    "        if emo == \"ps\":\n",
    "            emotion_df.append((\"surprise\", os.path.join(Tess, dir, wav)))\n",
    "        else:\n",
    "            emotion_df.append((emo, os.path.join(Tess, dir, wav)))\n",
    "\n",
    "\n",
    "Tess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Tess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b4b92f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11682, 2)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's concat all datasets together for doing some analysis\n",
    "df = pd.concat([Ravdess_df, Crema_df, Tess_df], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "582b2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sad</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surprise</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surprise</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion                                               Path\n",
       "0     angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "1      fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "2      fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "3     angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "4   disgust  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "5       sad  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "6       sad  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "7   disgust  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "8  surprise  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "9  surprise  data/Ravdess/audio_speech_actors_01-24/Actor_1..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0ec90e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.title(\"Count of emotions:\")\n",
    "sns.countplot(x=df[\"Emotion\"])\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ed5e3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data, random=False, rate=0.035, threshold=0.075):\n",
    "    \"\"\"Add some noise to sound sample. Use random if you want to add random noise with some threshold.\n",
    "    Or use rate Random=False and rate for always adding fixed noise.\"\"\"\n",
    "    if random:\n",
    "        rate = np.random.random() * threshold\n",
    "    noise_amp = rate*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    \"\"\"Stretching data with some rate.\"\"\"\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data, rate=1000):\n",
    "    \"\"\"Shifting data with some rate\"\"\"\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*rate)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7, random=False):\n",
    "    if random:\n",
    "        pitch_factor = np.random.random() * pitch_factor\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c9073ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>data/Ravdess/audio_speech_actors_01-24/Actor_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Path\n",
       "0    angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "1     fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "2     fear  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "3    angry  data/Ravdess/audio_speech_actors_01-24/Actor_1...\n",
       "4  disgust  data/Ravdess/audio_speech_actors_01-24/Actor_1..."
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aead40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, frame_length, hop_length):\n",
    "    for i in range(0, len(data), hop_length):\n",
    "        yield data[i:i+frame_length]\n",
    "\n",
    "# Zero Crossing Rate\n",
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "\n",
    "def energy(data, frame_length=2048, hop_length=512):\n",
    "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
    "    return en / frame_length\n",
    "\n",
    "\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "\n",
    "def entropy_of_energy(data, frame_length=2048, hop_length=512):\n",
    "    energies = energy(data, frame_length, hop_length)\n",
    "    energies /= np.sum(energies)\n",
    "\n",
    "    entropy = 0.0\n",
    "    entropy -= energies * np.log2(energies)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def spc(data, sr, frame_length=2048, hop_length=512):\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spectral_centroid)\n",
    "\n",
    "\n",
    "# def spc_entropy(data, sr):\n",
    "#     spc_en = spectral_entropy(data, sf=sr, method=\"fft\")\n",
    "#     return spc_en\n",
    "\n",
    "def spc_flux(data):\n",
    "    isSpectrum = data.ndim == 1\n",
    "    if isSpectrum:\n",
    "        data = np.expand_dims(data, axis=1)\n",
    "\n",
    "    X = np.c_[data[:, 0], data]\n",
    "    af_Delta_X = np.diff(X, 1, axis=1)\n",
    "    vsf = np.sqrt((np.power(af_Delta_X, 2).sum(axis=0))) / X.shape[0]\n",
    "\n",
    "    return np.squeeze(vsf) if isSpectrum else vsf\n",
    "\n",
    "\n",
    "def spc_rollof(data, sr, frame_length=2048, hop_length=512):\n",
    "    spcrollof = librosa.feature.spectral_rolloff(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spcrollof)\n",
    "\n",
    "\n",
    "def chroma_stft(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
    "    return np.squeeze(chroma_stft.T) if not flatten else np.ravel(chroma_stft.T)\n",
    "\n",
    "\n",
    "def mel_spc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mel = librosa.feature.melspectrogram(y=data, sr=sr)\n",
    "    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)\n",
    "\n",
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n",
    "    return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d91b531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        # np.mean(energy(data, frame_length, hop_length),axis=0),\n",
    "                        # np.mean(entropy_of_energy(data, frame_length, hop_length), axis=0),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        # spc(data, sr, frame_length, hop_length),\n",
    "                        # spc_entropy(data, sr),\n",
    "                        # spc_flux(data),\n",
    "                        # spc_rollof(data, sr, frame_length, hop_length),\n",
    "                        # chroma_stft(data, sr, frame_length, hop_length),\n",
    "                        # mel_spc(data, sr, frame_length, hop_length, flatten=True)\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                                    ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "df72cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path, duration=2.5, offset=0.6):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
    "\n",
    "     # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    # data with noise\n",
    "    noise_data = noise(data, random=True)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    # data with pitching\n",
    "    pitched_data = pitch(data, sample_rate, random=True)\n",
    "    res3 = extract_features(pitched_data, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    # data with pitching and white_noise\n",
    "    new_data = pitch(data, sample_rate, random=True)\n",
    "    data_noise_pitch = noise(new_data, random=True)\n",
    "    res3 = extract_features(data_noise_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4aff6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path, duration=2.5, offset=0.6):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
    "\n",
    "     # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    # data with noise\n",
    "    noise_data = noise(data, random=True)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    # data with pitching\n",
    "    pitched_data = pitch(data, sample_rate, random=True)\n",
    "    res3 = extract_features(pitched_data, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    # data with pitching and white_noise\n",
    "    new_data = pitch(data, sample_rate, random=True)\n",
    "    data_noise_pitch = noise(new_data, random=True)\n",
    "    res3 = extract_features(data_noise_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "51735d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature processing...\n",
      "0 samples has been processed...\n",
      "100 samples has been processed...\n",
      "200 samples has been processed...\n",
      "300 samples has been processed...\n",
      "400 samples has been processed...\n",
      "500 samples has been processed...\n",
      "600 samples has been processed...\n",
      "700 samples has been processed...\n",
      "800 samples has been processed...\n",
      "900 samples has been processed...\n",
      "1000 samples has been processed...\n",
      "1100 samples has been processed...\n",
      "1200 samples has been processed...\n",
      "1300 samples has been processed...\n",
      "1400 samples has been processed...\n",
      "1500 samples has been processed...\n",
      "1600 samples has been processed...\n",
      "1700 samples has been processed...\n",
      "1800 samples has been processed...\n",
      "1900 samples has been processed...\n",
      "2000 samples has been processed...\n",
      "2100 samples has been processed...\n",
      "2200 samples has been processed...\n",
      "2300 samples has been processed...\n",
      "2400 samples has been processed...\n",
      "2500 samples has been processed...\n",
      "2600 samples has been processed...\n",
      "2700 samples has been processed...\n",
      "2800 samples has been processed...\n",
      "2900 samples has been processed...\n",
      "3000 samples has been processed...\n",
      "3100 samples has been processed...\n",
      "3200 samples has been processed...\n",
      "3300 samples has been processed...\n",
      "3400 samples has been processed...\n",
      "3500 samples has been processed...\n",
      "3600 samples has been processed...\n",
      "3700 samples has been processed...\n",
      "3800 samples has been processed...\n",
      "3900 samples has been processed...\n",
      "4000 samples has been processed...\n",
      "4100 samples has been processed...\n",
      "4200 samples has been processed...\n",
      "4300 samples has been processed...\n",
      "4400 samples has been processed...\n",
      "4500 samples has been processed...\n",
      "4600 samples has been processed...\n",
      "4700 samples has been processed...\n",
      "4800 samples has been processed...\n",
      "4900 samples has been processed...\n",
      "5000 samples has been processed...\n",
      "5100 samples has been processed...\n",
      "5200 samples has been processed...\n",
      "5300 samples has been processed...\n",
      "5400 samples has been processed...\n",
      "5500 samples has been processed...\n",
      "5600 samples has been processed...\n",
      "5700 samples has been processed...\n",
      "5800 samples has been processed...\n",
      "5900 samples has been processed...\n",
      "6000 samples has been processed...\n",
      "6100 samples has been processed...\n",
      "6200 samples has been processed...\n",
      "6300 samples has been processed...\n",
      "6400 samples has been processed...\n",
      "6500 samples has been processed...\n",
      "6600 samples has been processed...\n",
      "6700 samples has been processed...\n",
      "6800 samples has been processed...\n",
      "6900 samples has been processed...\n",
      "7000 samples has been processed...\n",
      "7100 samples has been processed...\n",
      "7200 samples has been processed...\n",
      "7300 samples has been processed...\n",
      "7400 samples has been processed...\n",
      "7500 samples has been processed...\n",
      "7600 samples has been processed...\n",
      "7700 samples has been processed...\n",
      "7800 samples has been processed...\n",
      "7900 samples has been processed...\n",
      "8000 samples has been processed...\n",
      "8100 samples has been processed...\n",
      "8200 samples has been processed...\n",
      "8300 samples has been processed...\n",
      "8400 samples has been processed...\n",
      "8500 samples has been processed...\n",
      "8600 samples has been processed...\n",
      "8700 samples has been processed...\n",
      "8800 samples has been processed...\n",
      "8900 samples has been processed...\n",
      "9000 samples has been processed...\n",
      "9100 samples has been processed...\n",
      "9200 samples has been processed...\n",
      "9300 samples has been processed...\n",
      "9400 samples has been processed...\n",
      "9500 samples has been processed...\n",
      "9600 samples has been processed...\n",
      "9700 samples has been processed...\n",
      "9800 samples has been processed...\n",
      "9900 samples has been processed...\n",
      "10000 samples has been processed...\n",
      "10100 samples has been processed...\n",
      "10200 samples has been processed...\n",
      "10300 samples has been processed...\n",
      "10400 samples has been processed...\n",
      "10500 samples has been processed...\n",
      "10600 samples has been processed...\n",
      "10700 samples has been processed...\n",
      "10800 samples has been processed...\n",
      "10900 samples has been processed...\n",
      "11000 samples has been processed...\n",
      "11100 samples has been processed...\n",
      "11200 samples has been processed...\n",
      "11300 samples has been processed...\n",
      "11400 samples has been processed...\n",
      "11500 samples has been processed...\n",
      "11600 samples has been processed...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "print(\"Feature processing...\")\n",
    "for path, emotion, ind in zip(df.Path, df.Emotion, range(df.Path.shape[0])):\n",
    "    features = get_features(path)\n",
    "    if ind % 100 == 0:\n",
    "        print(f\"{ind} samples has been processed...\")\n",
    "    for ele in features:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f6f500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = \"./features.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fec2afb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.450195</td>\n",
       "      <td>0.645996</td>\n",
       "      <td>0.669434</td>\n",
       "      <td>0.463379</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857723</td>\n",
       "      <td>0.094373</td>\n",
       "      <td>-0.881573</td>\n",
       "      <td>-2.292750</td>\n",
       "      <td>-3.886958</td>\n",
       "      <td>-5.131240</td>\n",
       "      <td>-5.645916</td>\n",
       "      <td>-5.510086</td>\n",
       "      <td>-5.180732</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.254395</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>0.498047</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.764024</td>\n",
       "      <td>0.144398</td>\n",
       "      <td>-0.556579</td>\n",
       "      <td>-2.151318</td>\n",
       "      <td>2.546728</td>\n",
       "      <td>-0.809257</td>\n",
       "      <td>-2.989112</td>\n",
       "      <td>0.250804</td>\n",
       "      <td>1.991322</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.395508</td>\n",
       "      <td>0.464355</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554514</td>\n",
       "      <td>0.352726</td>\n",
       "      <td>-0.245254</td>\n",
       "      <td>-1.296545</td>\n",
       "      <td>-2.468369</td>\n",
       "      <td>-3.322303</td>\n",
       "      <td>-3.681481</td>\n",
       "      <td>-3.752230</td>\n",
       "      <td>-3.896340</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.497070</td>\n",
       "      <td>0.497559</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>...</td>\n",
       "      <td>3.509855</td>\n",
       "      <td>3.742382</td>\n",
       "      <td>1.238459</td>\n",
       "      <td>0.923107</td>\n",
       "      <td>2.620041</td>\n",
       "      <td>2.836663</td>\n",
       "      <td>1.651290</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.912133</td>\n",
       "      <td>8.608450</td>\n",
       "      <td>6.253413</td>\n",
       "      <td>-3.000357</td>\n",
       "      <td>-3.556973</td>\n",
       "      <td>-0.099310</td>\n",
       "      <td>0.656089</td>\n",
       "      <td>-3.026766</td>\n",
       "      <td>-6.480430</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.051758  0.257812  0.450195  0.645996  0.669434  0.463379   \n",
       "1  0.254395  0.380371  0.500000  0.500488  0.502441  0.508789  0.513672   \n",
       "2  0.197266  0.288086  0.374512  0.363281  0.326172  0.309570  0.335938   \n",
       "3  0.259766  0.389160  0.516602  0.514160  0.500000  0.503906  0.497070   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          7         8         9  ...      2367      2368      2369      2370  \\\n",
       "0  0.270996  0.211914  0.354004  ...  0.857723  0.094373 -0.881573 -2.292750   \n",
       "1  0.514160  0.498047  0.488281  ... -0.764024  0.144398 -0.556579 -2.151318   \n",
       "2  0.395508  0.464355  0.529297  ...  0.554514  0.352726 -0.245254 -1.296545   \n",
       "3  0.497559  0.509277  0.509277  ...  3.509855  3.742382  1.238459  0.923107   \n",
       "4  0.000000  0.000000  0.000000  ... -3.912133  8.608450  6.253413 -3.000357   \n",
       "\n",
       "       2371      2372      2373      2374      2375  labels  \n",
       "0 -3.886958 -5.131240 -5.645916 -5.510086 -5.180732   angry  \n",
       "1  2.546728 -0.809257 -2.989112  0.250804  1.991322   angry  \n",
       "2 -2.468369 -3.322303 -3.681481 -3.752230 -3.896340   angry  \n",
       "3  2.620041  2.836663  1.651290  0.267604 -0.034477   angry  \n",
       "4 -3.556973 -0.099310  0.656089 -3.026766 -6.480430    fear  \n",
       "\n",
       "[5 rows x 2377 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df = pd.DataFrame(X)\n",
    "extracted_df[\"labels\"] = Y\n",
    "extracted_df.to_csv(features_path, index=False)\n",
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6cd4bc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46728, 2377)\n"
     ]
    }
   ],
   "source": [
    "extracted_df = pd.read_csv(features_path)\n",
    "print(extracted_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "40763aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "2372      False\n",
      "2373      False\n",
      "2374      False\n",
      "2375      False\n",
      "labels    False\n",
      "Length: 2377, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46728, 2377)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN with 0\n",
    "extracted_df = extracted_df.fillna(0)\n",
    "print(extracted_df.isna().any())\n",
    "extracted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "660af93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2367</th>\n",
       "      <th>2368</th>\n",
       "      <th>2369</th>\n",
       "      <th>2370</th>\n",
       "      <th>2371</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051758</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.450195</td>\n",
       "      <td>0.645996</td>\n",
       "      <td>0.669434</td>\n",
       "      <td>0.463379</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857723</td>\n",
       "      <td>0.094373</td>\n",
       "      <td>-0.881573</td>\n",
       "      <td>-2.292750</td>\n",
       "      <td>-3.886958</td>\n",
       "      <td>-5.131240</td>\n",
       "      <td>-5.645916</td>\n",
       "      <td>-5.510086</td>\n",
       "      <td>-5.180732</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.254395</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>0.498047</td>\n",
       "      <td>0.488281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.764024</td>\n",
       "      <td>0.144398</td>\n",
       "      <td>-0.556579</td>\n",
       "      <td>-2.151318</td>\n",
       "      <td>2.546728</td>\n",
       "      <td>-0.809257</td>\n",
       "      <td>-2.989112</td>\n",
       "      <td>0.250804</td>\n",
       "      <td>1.991322</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.395508</td>\n",
       "      <td>0.464355</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554514</td>\n",
       "      <td>0.352726</td>\n",
       "      <td>-0.245254</td>\n",
       "      <td>-1.296545</td>\n",
       "      <td>-2.468369</td>\n",
       "      <td>-3.322303</td>\n",
       "      <td>-3.681481</td>\n",
       "      <td>-3.752230</td>\n",
       "      <td>-3.896340</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.497070</td>\n",
       "      <td>0.497559</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>...</td>\n",
       "      <td>3.509855</td>\n",
       "      <td>3.742382</td>\n",
       "      <td>1.238459</td>\n",
       "      <td>0.923107</td>\n",
       "      <td>2.620041</td>\n",
       "      <td>2.836663</td>\n",
       "      <td>1.651290</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.912133</td>\n",
       "      <td>8.608450</td>\n",
       "      <td>6.253413</td>\n",
       "      <td>-3.000357</td>\n",
       "      <td>-3.556973</td>\n",
       "      <td>-0.099310</td>\n",
       "      <td>0.656089</td>\n",
       "      <td>-3.026766</td>\n",
       "      <td>-6.480430</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.051758  0.257812  0.450195  0.645996  0.669434  0.463379   \n",
       "1  0.254395  0.380371  0.500000  0.500488  0.502441  0.508789  0.513672   \n",
       "2  0.197266  0.288086  0.374512  0.363281  0.326172  0.309570  0.335938   \n",
       "3  0.259766  0.389160  0.516602  0.514160  0.500000  0.503906  0.497070   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          7         8         9  ...      2367      2368      2369      2370  \\\n",
       "0  0.270996  0.211914  0.354004  ...  0.857723  0.094373 -0.881573 -2.292750   \n",
       "1  0.514160  0.498047  0.488281  ... -0.764024  0.144398 -0.556579 -2.151318   \n",
       "2  0.395508  0.464355  0.529297  ...  0.554514  0.352726 -0.245254 -1.296545   \n",
       "3  0.497559  0.509277  0.509277  ...  3.509855  3.742382  1.238459  0.923107   \n",
       "4  0.000000  0.000000  0.000000  ... -3.912133  8.608450  6.253413 -3.000357   \n",
       "\n",
       "       2371      2372      2373      2374      2375  labels  \n",
       "0 -3.886958 -5.131240 -5.645916 -5.510086 -5.180732   angry  \n",
       "1  2.546728 -0.809257 -2.989112  0.250804  1.991322   angry  \n",
       "2 -2.468369 -3.322303 -3.681481 -3.752230 -3.896340   angry  \n",
       "3  2.620041  2.836663  1.651290  0.267604 -0.034477   angry  \n",
       "4 -3.556973 -0.099310  0.656089 -3.026766 -6.480430    fear  \n",
       "\n",
       "[5 rows x 2377 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76c1449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extracted_df.drop(labels=\"labels\", axis=1)\n",
    "Y = extracted_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4d9472b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "Y = to_categorical(lb.fit_transform(Y))\n",
    "print(lb.classes_)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3431b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fbcaab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37382, 2376), (9346, 2376), (37382, 7), (9346, 7))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.2, shuffle=True)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "119903be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33643, 2376), (9346, 2376), (3739, 2376), (33643, 7), (9346, 7), (3739, 7))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.1, shuffle=True)\n",
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c272d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33643, 2376), (9346, 2376), (3739, 2376), (33643, 7), (9346, 7), (3739, 7))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd545a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33643, 2376, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to use 1-dimensional CNN which need specifical shape:\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_val = np.expand_dims(X_val, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "26fb500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor =\"val_acc\",\n",
    "                              mode = 'auto', patience = 5,\n",
    "                              restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b2df10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "050e4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b40f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\",\n",
    "                        input_shape=(X_train.shape[1], 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(layers.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"acc\", f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "788c2b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2376, 512)         3072      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2376, 512)         2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 1188, 512)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1188, 512)         1311232   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1188, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 594, 512)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 594, 256)          655616    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 594, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 297, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 297, 256)          196864    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 297, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 149, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 149, 128)          98432     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 149, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 75, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4915712   \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7193223 (27.44 MB)\n",
      "Trainable params: 7188871 (27.42 MB)\n",
      "Non-trainable params: 4352 (17.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4118a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bc781515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 49/526 [=>............................] - ETA: 18:44 - loss: 2.3112 - acc: 0.3042 - f1_m: 0.2188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[1;32m      2\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m      3\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[earlystopping, learning_rate_reduction])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=EPOCHS, batch_size=batch_size,\n",
    "                    callbacks=[earlystopping, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")\n",
    "\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_acc']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(train_loss, label = 'Training Loss')\n",
    "ax[0].plot(test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(train_acc, label = 'Training Accuracy')\n",
    "ax[1].plot(test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30883c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_check = np.argmax(y_test, axis=1)\n",
    "y_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed551c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_check, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81968a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"./res_model.h5\"\n",
    "\n",
    "model.save(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ac642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5c4887bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "['disgust']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def get_features(path, duration=2.5, offset=0.6):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "#     data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
    "\n",
    "    # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    # data with noise\n",
    "    noise_data = noise(data, random=True)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    # data with pitching\n",
    "    pitched_data = pitch(data, sample_rate, random=True)\n",
    "    res3 = extract_features(pitched_data, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    # data with pitching and white_noise\n",
    "    new_data = pitch(data, sample_rate, random=True)\n",
    "    data_noise_pitch = noise(new_data, random=True)\n",
    "    res3 = extract_features(data_noise_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "    # Flatten the result to a single vector per sample\n",
    "    flattened_result = result.flatten()\n",
    "\n",
    "    # Make sure the flattened result has length 2376\n",
    "    # You might need to adjust this depending on how you want to handle different lengths\n",
    "    flattened_result = np.resize(flattened_result, 2376)\n",
    "\n",
    "    return flattened_result\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('res_model.h5', custom_objects={'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
    "# Usage\n",
    "data, sample_rate = librosa.load('/Users/taekwan/Desktop/1001_DFA_SAD_XX.wav', duration=2.5, offset=0.6)\n",
    "features = get_features(data, sample_rate)\n",
    "features = features.reshape(1, 2376, 1)  # Reshape for the model: 1 sample, 2376 features, 1 dimension\n",
    "prediction = model.predict(features)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "predicted_emotion = lb.inverse_transform(predicted_class)\n",
    "print(predicted_emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673f915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
